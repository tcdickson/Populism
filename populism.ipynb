{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-13T16:31:40.728545Z",
     "start_time": "2025-08-13T16:31:39.717105Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Final_Populism.csv')"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T18:13:49.193511Z",
     "start_time": "2025-08-12T18:13:49.185704Z"
    }
   },
   "cell_type": "code",
   "source": "df",
   "id": "98cf12aa163be60e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                     Summary_Embeddings  \\\n",
       "0     [-0.029149754, -0.021904264, 0.0021603003, -0....   \n",
       "1     [0.019964693, 0.010486043, 0.027138552, 0.0468...   \n",
       "2     [-0.011785262, -0.005118389, -0.028711798, 0.0...   \n",
       "3     [-0.046097253, -0.027319714, 0.007871007, -0.0...   \n",
       "4     [-0.055969328, 0.08520521, 0.015029931, 0.0698...   \n",
       "...                                                 ...   \n",
       "9892  [-0.057788845, 0.0046745464, -0.011104433, 0.0...   \n",
       "9893  [-0.027253903, -0.0062221605, -0.051059105, 0....   \n",
       "9894  [-0.04918098, 0.00316158, -0.027780691, 0.0190...   \n",
       "9895  [-0.054796062, 0.019674687, -0.033823974, 0.03...   \n",
       "9896  [-0.034596924, 6.230459E-4, -0.017634058, 0.01...   \n",
       "\n",
       "                                                Summary  \\\n",
       "0     Donnchadh Ó Laoghaire of Sinn Féin criticized ...   \n",
       "1     Donnchadh Ó Laoghaire, Sinn Féin's spokesperso...   \n",
       "2     Donnchadh Ó Laoghaire, a Sinn Féin TD, urged t...   \n",
       "3     Donáth Anna, a Momentum EP-képviselője, az Eur...   \n",
       "4     Douglas Hoyos criticizes the Austrian governme...   \n",
       "...                                                 ...   \n",
       "9892  The text highlights growing protests against E...   \n",
       "9893  The text highlights support for the PVV party,...   \n",
       "9894  The text highlights the Dutch government's mis...   \n",
       "9895  The text highlights the ELAM party's oppositio...   \n",
       "9896  The text highlights the SP's grassroots approa...   \n",
       "\n",
       "                                          Original_Text  \\\n",
       "0     Sinn Féin spokesperson on Social Protection, D...   \n",
       "1     Lack of space in our schools must be addressed...   \n",
       "2     We must safeguard the future of League of Irel...   \n",
       "3      Szerző: Momentum Mozgalom | máj 31, 2023 | Mé...   \n",
       "4     Douglas Hoyos: \"Eine Taskforce einzuführen ist...   \n",
       "...                                                 ...   \n",
       "9892  Nu de Europese top van regeringsleiders op 14 ...   \n",
       "9893  PVV +2 zetels!Nederlanders willen hun eigen la...   \n",
       "9894  Tienduizenden mensen zijn het slachtoffer gewo...   \n",
       "9895  Στις 8 Ιουλίου του 2018 ΔΗΣΥ και ΔΗΚΟ ψήφισαν ...   \n",
       "9896  De SP groeide ooit uit van een verzameling lok...   \n",
       "\n",
       "                                          Article_Title  Is_Populist  \n",
       "0     No sense in government’s all-in approach to EU...            0  \n",
       "1     Lack of space in our schools must be addressed...            0  \n",
       "2     We must safeguard the future of League of Irel...            0  \n",
       "3     Donáth Anna: Európa a megoldás a magyar oktatá...            0  \n",
       "4     Douglas Hoyos: Eine Taskforce einzuführen ist ...            0  \n",
       "...                                                 ...          ...  \n",
       "9892                   Veel protestacties rond Euro-Top            1  \n",
       "9893                                    PVV +2 ZETELS!!            1  \n",
       "9894  Aftreden kabinet maakt weg vrij voor een eerli...            1  \n",
       "9895  Άρχισαν οι ηλεκτρονικές εκποιήσεις – Το ΕΛΑΜ σ...            1  \n",
       "9896  De SP groeide ooit uit van een verzameling lok...            0  \n",
       "\n",
       "[9897 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary_Embeddings</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Original_Text</th>\n",
       "      <th>Article_Title</th>\n",
       "      <th>Is_Populist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.029149754, -0.021904264, 0.0021603003, -0....</td>\n",
       "      <td>Donnchadh Ó Laoghaire of Sinn Féin criticized ...</td>\n",
       "      <td>Sinn Féin spokesperson on Social Protection, D...</td>\n",
       "      <td>No sense in government’s all-in approach to EU...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.019964693, 0.010486043, 0.027138552, 0.0468...</td>\n",
       "      <td>Donnchadh Ó Laoghaire, Sinn Féin's spokesperso...</td>\n",
       "      <td>Lack of space in our schools must be addressed...</td>\n",
       "      <td>Lack of space in our schools must be addressed...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.011785262, -0.005118389, -0.028711798, 0.0...</td>\n",
       "      <td>Donnchadh Ó Laoghaire, a Sinn Féin TD, urged t...</td>\n",
       "      <td>We must safeguard the future of League of Irel...</td>\n",
       "      <td>We must safeguard the future of League of Irel...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.046097253, -0.027319714, 0.007871007, -0.0...</td>\n",
       "      <td>Donáth Anna, a Momentum EP-képviselője, az Eur...</td>\n",
       "      <td>Szerző: Momentum Mozgalom | máj 31, 2023 | Mé...</td>\n",
       "      <td>Donáth Anna: Európa a megoldás a magyar oktatá...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-0.055969328, 0.08520521, 0.015029931, 0.0698...</td>\n",
       "      <td>Douglas Hoyos criticizes the Austrian governme...</td>\n",
       "      <td>Douglas Hoyos: \"Eine Taskforce einzuführen ist...</td>\n",
       "      <td>Douglas Hoyos: Eine Taskforce einzuführen ist ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9892</th>\n",
       "      <td>[-0.057788845, 0.0046745464, -0.011104433, 0.0...</td>\n",
       "      <td>The text highlights growing protests against E...</td>\n",
       "      <td>Nu de Europese top van regeringsleiders op 14 ...</td>\n",
       "      <td>Veel protestacties rond Euro-Top</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9893</th>\n",
       "      <td>[-0.027253903, -0.0062221605, -0.051059105, 0....</td>\n",
       "      <td>The text highlights support for the PVV party,...</td>\n",
       "      <td>PVV +2 zetels!Nederlanders willen hun eigen la...</td>\n",
       "      <td>PVV +2 ZETELS!!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9894</th>\n",
       "      <td>[-0.04918098, 0.00316158, -0.027780691, 0.0190...</td>\n",
       "      <td>The text highlights the Dutch government's mis...</td>\n",
       "      <td>Tienduizenden mensen zijn het slachtoffer gewo...</td>\n",
       "      <td>Aftreden kabinet maakt weg vrij voor een eerli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9895</th>\n",
       "      <td>[-0.054796062, 0.019674687, -0.033823974, 0.03...</td>\n",
       "      <td>The text highlights the ELAM party's oppositio...</td>\n",
       "      <td>Στις 8 Ιουλίου του 2018 ΔΗΣΥ και ΔΗΚΟ ψήφισαν ...</td>\n",
       "      <td>Άρχισαν οι ηλεκτρονικές εκποιήσεις – Το ΕΛΑΜ σ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9896</th>\n",
       "      <td>[-0.034596924, 6.230459E-4, -0.017634058, 0.01...</td>\n",
       "      <td>The text highlights the SP's grassroots approa...</td>\n",
       "      <td>De SP groeide ooit uit van een verzameling lok...</td>\n",
       "      <td>De SP groeide ooit uit van een verzameling lok...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9897 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T16:31:40.921621Z",
     "start_time": "2025-08-13T16:31:40.916530Z"
    }
   },
   "cell_type": "code",
   "source": "df = df[['Summary', 'Original_Text', 'Article_Title','Is_Populist']]",
   "id": "216fdea5bbe29ff5",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-08-13T16:32:05.155549Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# pip install -U transformers datasets peft accelerate evaluate rouge-score bitsandbytes\n",
    "\n",
    "import os, random, numpy as np, pandas as pd, torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq,\n",
    "    TrainingArguments, Trainer\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import evaluate\n",
    "\n",
    "MODEL_NAME = \"facebook/bart-base\"   \n",
    "MAX_SRC = 1024\n",
    "MAX_SUM = 128\n",
    "DROP_TITLE_PROB = 0.5  \n",
    "USE_LORA = True\n",
    "\n",
    "\n",
    "df['Is_Populist'] = df['Is_Populist'].astype(int).clip(0,1)\n",
    "\n",
    "def make_prompt(title, text, may_drop=False):\n",
    "    use_title = bool(title) and (not may_drop or random.random() > DROP_TITLE_PROB)\n",
    "    prefix = (title.strip() + \". \") if use_title else \"\"\n",
    "    return (prefix + (text or \"\")).strip()\n",
    "\n",
    "def row_to_examples(row, may_drop=False):\n",
    "    x_sum = \"summarize: \" + make_prompt(row['Article_Title'], row['Original_Text'], may_drop=may_drop)\n",
    "    x_cls = \"classify_populism: \" + make_prompt(row['Article_Title'], row['Original_Text'], may_drop=may_drop)\n",
    "    return [\n",
    "        {\"task\":\"summarize\", \"input\": x_sum, \"target\": row[\"Summary\"]},\n",
    "        {\"task\":\"classify\",  \"input\": x_cls, \"target\": str(int(row[\"Is_Populist\"]))}\n",
    "    ]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['Is_Populist'])\n",
    "val_df, test_df   = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df['Is_Populist'])\n",
    "\n",
    "train_examples = [ex for _, r in train_df.iterrows() for ex in row_to_examples(r, may_drop=True)]\n",
    "val_examples   = [ex for _, r in val_df.iterrows()   for ex in row_to_examples(r, may_drop=False)]\n",
    "test_examples  = [ex for _, r in test_df.iterrows()  for ex in row_to_examples(r, may_drop=False)]\n",
    "\n",
    "train_ds = Dataset.from_list(train_examples)\n",
    "val_ds   = Dataset.from_list(val_examples)\n",
    "test_ds  = Dataset.from_list(test_examples)\n",
    "\n",
    "val_sum  = val_ds.filter(lambda ex: ex[\"task\"]==\"summarize\")\n",
    "val_cls  = val_ds.filter(lambda ex: ex[\"task\"]==\"classify\")\n",
    "test_sum = test_ds.filter(lambda ex: ex[\"task\"]==\"summarize\")\n",
    "test_cls = test_ds.filter(lambda ex: ex[\"task\"]==\"classify\")\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "tok.padding_side = \"right\"  \n",
    "\n",
    "def tokenize_fn(batch):\n",
    "    model_inputs = tok(\n",
    "        batch[\"input\"], max_length=MAX_SRC, truncation=True, padding=\"max_length\"\n",
    "    )\n",
    "    labels = tok(\n",
    "        text_target=batch[\"target\"], max_length=MAX_SUM, truncation=True, padding=\"max_length\"\n",
    "    )\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "train_tok = train_ds.map(tokenize_fn, batched=True, remove_columns=train_ds.column_names)\n",
    "val_sum_tok  = val_sum.map(tokenize_fn, batched=True, remove_columns=val_sum.column_names)\n",
    "val_cls_tok  = val_cls.map(tokenize_fn, batched=True, remove_columns=val_cls.column_names)\n",
    "test_sum_tok = test_sum.map(tokenize_fn, batched=True, remove_columns=test_sum.column_names)\n",
    "test_cls_tok = test_cls.map(tokenize_fn, batched=True, remove_columns=test_cls.column_names)\n",
    "\n",
    "\n",
    "base = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=(torch.float16 if torch.cuda.is_available() else torch.float32),\n",
    "    attn_implementation=\"sdpa\"  # switch to \"eager\" if you see kernel issues\n",
    ").to(\"cuda\")\n",
    "\n",
    "if USE_LORA:\n",
    "    peft_cfg = LoraConfig(task_type=\"SEQ_2_SEQ_LM\", r=16, lora_alpha=32, lora_dropout=0.05)\n",
    "    model = get_peft_model(base, peft_cfg)\n",
    "else:\n",
    "    model = base\n",
    "\n",
    "collator = DataCollatorForSeq2Seq(tokenizer=tok, model=model)\n",
    "\n",
    "    \n",
    "    \n",
    "rouge = evaluate.load(\"rouge\")\n",
    "acc   = evaluate.load(\"accuracy\"); prec = evaluate.load(\"precision\")\n",
    "rec   = evaluate.load(\"recall\");   f1   = evaluate.load(\"f1\")\n",
    "\n",
    "def _decode(pred_ids, label_ids):\n",
    "    pred_ids  = np.where(pred_ids  != -100, pred_ids,  tok.pad_token_id)\n",
    "    label_ids = np.where(label_ids != -100, label_ids, tok.pad_token_id)\n",
    "    preds  = tok.batch_decode(pred_ids,  skip_special_tokens=True)\n",
    "    labels = tok.batch_decode(label_ids, skip_special_tokens=True)\n",
    "    return preds, labels\n",
    "\n",
    "def summarize_metrics(eval_pred):\n",
    "    pred_ids, label_ids = eval_pred\n",
    "    preds, labels = _decode(pred_ids, label_ids)\n",
    "    r = rouge.compute(predictions=preds, references=labels, use_stemmer=True)\n",
    "    return {f\"rouge_{k}\": v for k,v in r.items()}\n",
    "\n",
    "def classify_metrics(eval_pred):\n",
    "    pred_ids, label_ids = eval_pred\n",
    "    preds, labels = _decode(pred_ids, label_ids)\n",
    "    preds_bin  = [1 if (p.strip() and p.strip()[0]=='1') else 0 for p in preds]\n",
    "    labels_bin = [1 if (l.strip() and l.strip()[0]=='1') else 0 for l in labels]\n",
    "    return {\n",
    "        \"accuracy\":  acc.compute(predictions=preds_bin, references=labels_bin)[\"accuracy\"],\n",
    "        \"precision\": prec.compute(predictions=preds_bin, references=labels_bin)[\"precision\"],\n",
    "        \"recall\":    rec.compute(predictions=preds_bin, references=labels_bin)[\"recall\"],\n",
    "        \"f1\":        f1.compute(predictions=preds_bin, references=labels_bin)[\"f1\"],\n",
    "    }\n",
    "\n",
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"bart_multitask_lora\",\n",
    "    learning_rate=2e-4,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=1,        # << small eval batch\n",
    "    eval_accumulation_steps=32,          # << stream preds to CPU\n",
    "    gradient_accumulation_steps=4,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    bf16=False,                          # your T1000 won’t do bf16\n",
    "    save_strategy=\"epoch\",\n",
    "    save_safetensors=True,\n",
    "    save_total_limit=3,\n",
    "    load_best_model_at_end=False,\n",
    "    metric_for_best_model=\"eval_rougeLsum\",\n",
    "    greater_is_better=True,\n",
    "    logging_steps=50,\n",
    "    dataloader_pin_memory=True,\n",
    "    gradient_checkpointing=False,\n",
    "    optim=\"adamw_torch_fused\",\n",
    "    report_to=\"none\",\n",
    "    torch_compile=False,\n",
    "\n",
    "    # critical for memory-safe eval:\n",
    "    predict_with_generate=True,\n",
    "    generation_num_beams=1               # keep it cheap\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_tok,\n",
    "    eval_dataset=val_sum_tok,            # summarize-task split\n",
    "    tokenizer=tok,                       # ok to pass tokenizer here\n",
    "    data_collator=collator,\n",
    "    compute_metrics=summarize_metrics\n",
    ")\n",
    "\n",
    "\n",
    "try:\n",
    "    model.print_trainable_parameters()\n",
    "except Exception:\n",
    "    pass\n",
    "assert any(p.requires_grad for p in model.parameters()), \"No trainable parameters found.\"\n",
    "\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "dl = DataLoader(train_tok.with_format(\"torch\"), batch_size=2, shuffle=True, collate_fn=collator)\n",
    "b = next(iter(dl))\n",
    "b = {k: v.to(\"cuda\") for k,v in b.items()}\n",
    "\n",
    "print(\"model on:\", next(model.parameters()).device)\n",
    "model.train()\n",
    "out = model(**b)\n",
    "print(\"one-batch loss:\", float(out.loss))  \n",
    "out.loss.backward()\n",
    "print(\"grad present:\", any(p.grad is not None for p in model.parameters() if p.requires_grad))\n",
    "\n",
    "\n",
    "# Summarization (val)\n",
    "trainer.compute_metrics = summarize_metrics\n",
    "print(\"Validation – Summarization:\", trainer.evaluate(eval_dataset=val_sum_tok, metric_key_prefix=\"sum_val\"))\n",
    "\n",
    "\n",
    "trainer.evaluate(eval_dataset=val_cls_tok)\n",
    "\n",
    "trainer.compute_metrics = summarize_metrics\n",
    "print(\"Test – Summarization:\", trainer.evaluate(eval_dataset=test_sum_tok, metric_key_prefix=\"sum_test\"))\n",
    "\n",
    "# Classification (test)\n",
    "trainer.compute_metrics = classify_metrics\n",
    "print(\"Test – Classification:\", trainer.evaluate(eval_dataset=test_cls_tok, metric_key_prefix=\"cls_test\"))\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_summary_and_label(text: str):\n",
    "    device = next(model.parameters()).device\n",
    "    prompt_sum = \"summarize: \" + text.strip()\n",
    "    prompt_cls = \"classify_populism: \" + text.strip()\n",
    "\n",
    "    in_sum = tok(prompt_sum, return_tensors=\"pt\", truncation=True, max_length=MAX_SRC).to(device)\n",
    "    in_cls = tok(prompt_cls, return_tensors=\"pt\", truncation=True, max_length=MAX_SRC).to(device)\n",
    "\n",
    "    out_sum = model.generate(**in_sum, max_length=MAX_SUM)\n",
    "    out_cls = model.generate(**in_cls, max_length=8)\n",
    "\n",
    "    summary = tok.decode(out_sum[0], skip_special_tokens=True).strip()\n",
    "    label_s = tok.decode(out_cls[0], skip_special_tokens=True).strip()\n",
    "    is_pop  = 1 if (label_s and label_s[0]=='1') else 0\n",
    "    return summary, is_pop\n"
   ],
   "id": "ee83fa1e16229402",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: True, bf16: False, dtype: torch.float16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Filter:   0%|          | 0/1980 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c91564268c20464db0d215892d244f3b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Filter:   0%|          | 0/1980 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "96195ff869484fe681af40fa0d11767c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Filter:   0%|          | 0/1980 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dfca39340de64189878db2e9efacb38b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Filter:   0%|          | 0/1980 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "af69d4c091454644838f0bc7c53a9103"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/15834 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6f1ddcd20caa411e98f5ef28ed10cb76"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/990 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6140fe14c31a47d2b932ddb4a2a79931"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/990 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2736a96750af45c3afdc9ef94383a111"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/990 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "77cb527bb4fd416287c7ead68deac1e8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/990 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fbacfa8699c54aecaa45cdac16c867d6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1649834/1440693320.py:164: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 140,305,152 || trainable%: 0.6306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyty/anaconda3/envs/Palantir_Project/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='248' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 15/248 07:39 < 2:17:13, 0.03 it/s, Epoch 0.06/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "22f6bf6c37ec70d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "be733a170ce055d9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "@torch.no_grad()\n",
    "def predict_summary_and_label(text: str):\n",
    "    # User only provides Original_Text\n",
    "    prompt_sum = \"summarize: \" + text.strip()\n",
    "    prompt_cls = \"classify_populism: \" + text.strip()\n",
    "\n",
    "    in_sum = tok(prompt_sum, return_tensors=\"pt\", truncation=True, max_length=MAX_SRC).to(model.device)\n",
    "    in_cls = tok(prompt_cls, return_tensors=\"pt\", truncation=True, max_length=MAX_SRC).to(model.device)\n",
    "\n",
    "    out_sum = model.generate(**in_sum, max_length=MAX_SUM)\n",
    "    out_cls = model.generate(**in_cls, max_length=8)\n",
    "\n",
    "    summary = tok.decode(out_sum[0], skip_special_tokens=True).strip()\n",
    "    label_s = tok.decode(out_cls[0], skip_special_tokens=True).strip()\n",
    "    is_pop  = 1 if (label_s and label_s[0]=='1') else 0\n",
    "    return summary, is_pop\n"
   ],
   "id": "1ddc7c535e63f205"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
